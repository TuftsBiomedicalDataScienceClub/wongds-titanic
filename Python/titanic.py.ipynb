{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# titanic.py\n",
    "\n",
    "\n",
    "A Python-based solution for the Titanic machine learning problem on Kaggle.com. Based on myfirstforest.py from Kaggle.com.\n",
    "\n",
    "    / (root)\n",
    "    |- Kaggle Data/ [data files from Kaggle.com]\n",
    "    |- Python/ [current location]\n",
    "    |- R/\n",
    "\n",
    "## Notes:\n",
    "- Use the pandas library to use dataframes instead of complicated list/ \\\n",
    "  dictionary manipulation.\n",
    "- Use the RandomForestClassifier algorithm from the scikit-learn ensemble \\\n",
    "  module (sklearn.ensemble) to build randomized decision trees.\n",
    "- Use the numpy package of tools to perform some analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries and modules\n",
    "import csv # Module for working with CSV files\n",
    "import pprint # Module for human-friendly data printing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Relevant variables\n",
    "## Location of data files, relative to current directory\n",
    "DATA_DIR = '../Kaggle Data/' \n",
    "\n",
    "## Initialize Pretty Printer for future debugging use\n",
    "pp = pprint.PrettyPrinter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "## Training data\n",
    "## Load data into dataframe, don't bring headers\n",
    "train = pd.read_csv(DATA_DIR + 'train.csv', header=0)\n",
    "test = pd.read_csv(DATA_DIR + 'test.csv', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Clean up data\n",
    "## Strings to integers, fill in missing data.\n",
    "## Convert 'Sex' column to boolean 'IsMale'\n",
    "train['IsMale'] = train['Sex'].map({'female': 0, 'male': 1}).astype(int)\n",
    "test['IsMale'] = test['Sex'].map({'female': 0, 'male': 1}).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with pandas DataFrame objects\n",
    "- Use `pd.DataFrame.loc` to address row by number index, select column by header. This avoids the ambiguity when changing values that will result in a `SettingWithCopyWarning` error.\n",
    "- `pd.DataFrame.isnull()` returns a panda Series object with index and data.\n",
    "- Application of `.isnull()` to `train.Embarked` returns a Series object whose index contains the row numbers of missing Embarked data as pandas Index object.\n",
    "- Similarly, `train.Embarked` is a Series object, applying `Series.mode()` returns a Series object of length 1 with the mode, so address with index 0. Apply `Series.dropna()` to exclude these from the mode() call.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Clean up Embarked data.\n",
    "### Embarked: missing -> most common\n",
    "for row_num in train.Embarked[train.Embarked.isnull()].index:\n",
    "    train.loc[row_num, 'Embarked'] = train.Embarked.dropna().mode().values[0]\n",
    "\n",
    "for row_num in test.Embarked[test.Embarked.isnull()].index:\n",
    "    test.loc[row_num, 'Embarked'] = test.Embarked.dropna().mode().values[0]\n",
    "\n",
    "### Embarked: Map strings to list of ports, then change strings to integers\n",
    "PORTS = list(enumerate(np.unique(train.Embarked)))\n",
    "PORTS_TEST = list(enumerate(np.unique(test.Embarked)))\n",
    "#### Shorthand dictionary assignment, name as key, list index as value\n",
    "PORTS_DICT = {name : i for i, name in PORTS}\n",
    "PORTS_DICT_TEST = {name : i for i, name in PORTS_TEST}\n",
    "#### Use a lambda function, map the existing Embarked data x to PORTS_DICT \\\n",
    "#### using x as key and setting new value to integer value.\n",
    "train.Embarked = train.Embarked.map(lambda x: PORTS_DICT[x]).astype(int)\n",
    "test.Embarked = test.Embarked.map(lambda x: PORTS_DICT_TEST[x]).astype(int)\n",
    "\n",
    "### Age: missing -> median of all ages\n",
    "AGE_MEDIAN = train.Age.dropna().median()\n",
    "for row_num in train.Age[train.Age.isnull()].index:\n",
    "    train.loc[row_num, 'Age'] = AGE_MEDIAN\n",
    "\n",
    "AGE_MEDIAN_TEST = test.Age.dropna().median()    \n",
    "for row_num in test.Age[test.Age.isnull()].index:\n",
    "    test.loc[row_num, 'Age'] = AGE_MEDIAN_TEST\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### At least one fare is missing from the `test` dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Fare: missing -> median for fare class\n",
    "MEDIAN_FARE_TEST = np.zeros(len(np.unique(test.Pclass)))\n",
    "for f in range(0,len(np.unique(test.Pclass))):\n",
    "    MEDIAN_FARE_TEST[f] = test.loc[test.Pclass == f+1, 'Fare'].dropna().median()\n",
    "\n",
    "for row_num in test.Fare[test.Fare.isnull()].index:\n",
    "    temp_pclass = test.loc[row_num, 'Pclass'] - 1\n",
    "    test.loc[row_num, 'Fare'] = MEDIAN_FARE_TEST[temp_pclass]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Sex is now redundant with IsMale, drop the column\n",
    "- Cabin is absent for a large number of passengers, also non-integer\n",
    "- Names are unique, non-integer\n",
    "- Ticket numbers also unique, non-integer in many cases\n",
    "- Must remove PassengerId or they become part of prediction, values nonsense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Remove redundant column(s), remove non-integer columns\n",
    "train = train.drop(['Sex', 'Name', 'Ticket', 'Cabin', 'PassengerId'], axis=1)\n",
    "passenger_ids = test.PassengerId.values\n",
    "test = test.drop(['Sex', 'Name', 'Ticket', 'Cabin', 'PassengerId'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Cleaned data to np array\n",
    "train_data = train.values\n",
    "test_data = test.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine learning using `RandomForestClassifier`\n",
    "The `forest.fit()` call uses the training dataset to build a forest of decision trees. We set the number of trees to build using the `n_estimators` parameter when initializing the `RandomForestClassifier` object. The `fit()` call requries two arguments, with an optional third.\n",
    "- The first argument is a matrix of numerical values associated with the features we're interested in using to model the outcome, e.g. passenger class (Pclass), sex (IsMale), age (Age), number of siblings/spouses aboard (SibSp), number of parents/children aboard (Parch), and port of embarkation (Embarked). \n",
    "- The second argument is a matrix of the outcome(s) we want to model; in this case, the survival data (Survived).\n",
    "\n",
    "Scikit-learn ensemble documentation on RandomForestClassifier.fit(): http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier.fit\n",
    "\n",
    "To make this model more accurate, we can try to recombine some of the given data to make synthetic features that may have affected the survival of the passengers aboard the *Titanic*. These features would have to be added earlier, before certain columns were dropped from the dataframes. Possible features that oculd be added:\n",
    "- family size: attempts to keep a large family together might negatively impact survival of an individual (SibSp + Parch + 1)\n",
    "- age of youngest family member: could be change the difficulty of evacuating (probably correlate by name?)\n",
    "- age of oldest family member: similar to youngest family member\n",
    "- whether individual was a child: children could have been given priority on life boats or otherwise preferentially evacuated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Survived\n",
      "892        0.0\n",
      "893        0.0\n",
      "894        0.0\n",
      "895        1.0\n",
      "896        0.0\n",
      "897        0.0\n",
      "898        0.0\n",
      "899        0.0\n",
      "900        1.0\n",
      "901        0.0\n",
      "902        0.0\n",
      "903        0.0\n",
      "904        1.0\n",
      "905        0.0\n",
      "906        1.0\n",
      "907        1.0\n",
      "908        0.0\n",
      "909        1.0\n",
      "910        0.0\n",
      "911        0.0\n",
      "912        1.0\n",
      "913        0.0\n",
      "914        1.0\n",
      "915        1.0\n",
      "916        1.0\n",
      "917        0.0\n",
      "918        1.0\n",
      "919        1.0\n",
      "920        1.0\n",
      "921        0.0\n",
      "...        ...\n",
      "1280       0.0\n",
      "1281       0.0\n",
      "1282       0.0\n",
      "1283       1.0\n",
      "1284       0.0\n",
      "1285       0.0\n",
      "1286       0.0\n",
      "1287       1.0\n",
      "1288       0.0\n",
      "1289       1.0\n",
      "1290       0.0\n",
      "1291       0.0\n",
      "1292       1.0\n",
      "1293       0.0\n",
      "1294       1.0\n",
      "1295       0.0\n",
      "1296       0.0\n",
      "1297       1.0\n",
      "1298       0.0\n",
      "1299       0.0\n",
      "1300       1.0\n",
      "1301       1.0\n",
      "1302       1.0\n",
      "1303       1.0\n",
      "1304       0.0\n",
      "1305       0.0\n",
      "1306       1.0\n",
      "1307       0.0\n",
      "1308       0.0\n",
      "1309       1.0\n",
      "\n",
      "[418 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# Train the forest\n",
    "forest = RandomForestClassifier(n_estimators=100)\n",
    "forest = forest.fit(train_data[0::, 1::], train_data[0::, 0])\n",
    "\n",
    "# Make a prediction\n",
    "output = forest.predict(test_data)\n",
    "\n",
    "# Write to file\n",
    "predictions_file = open(\"myfirstforest.csv\", \"w\")\n",
    "open_file_object = csv.writer(predictions_file)\n",
    "open_file_object.writerow([\"PassengerId\",\"Survived\"])\n",
    "open_file_object.writerows(zip(passenger_ids, output))\n",
    "predictions_file.close()\n",
    "\n",
    "# Print the result here as well\n",
    "print(pd.DataFrame(data=output, index=passenger_ids, columns=['Survived']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
