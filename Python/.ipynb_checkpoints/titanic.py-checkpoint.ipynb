{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "titanic.py\n",
    "\n",
    "A Python-based solution for the Titanic machine learning problem on Kaggle.com. Based on myfirstforest.py from Kaggle.com.\n",
    "\n",
    "/ (root)\n",
    "|- Kaggle Data/ [data files from Kaggle.com]\n",
    "|- Python/ [current location]\n",
    "|- R/\n",
    "\n",
    "Notes:\n",
    "- Use the pandas library to use dataframes instead of complicated list/ \\\n",
    "  dictionary manipulation.\n",
    "- Use the RandomForestClassifier algorithm from the scikit-learn ensemble \\\n",
    "  module (sklearn.ensemble) to build randomized decision trees.\n",
    "- Use the numpy package of tools to perform some analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries and modules\n",
    "import csv # Module for working with CSV files\n",
    "import pprint # Module for human-friendly data printing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Relevant variables\n",
    "## Location of data files, relative to current directory\n",
    "DATA_DIR = '../Kaggle Data/' \n",
    "\n",
    "## Initialize Pretty Printer for future debugging use\n",
    "pp = pprint.PrettyPrinter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "## Training data\n",
    "## Load data into dataframe, don't bring headers\n",
    "train = pd.read_csv(DATA_DIR + 'train.csv', header=0)\n",
    "test = pd.read_csv(DATA_DIR + 'test.csv', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Clean up data\n",
    "## Strings to integers, fill in missing data.\n",
    "## Convert 'Sex' column to boolean 'IsMale'\n",
    "train['IsMale'] = train['Sex'].map({'female': 0, 'male': 1}).astype(int)\n",
    "test['IsMale'] = test['Sex'].map({'female': 0, 'male': 1}).astype(int)\n",
    "\n",
    "## Clean up Embarked data.\n",
    "### Embarked: missing -> most common\n",
    "#### pd.DataFrame.isnull() returns a panda Series object with index and data.\n",
    "#### Application to train.Embarked returns a Series object whose index \\\n",
    "#### contains the row numbers of missing Embarked data as pandas Index object.\n",
    "#### Similarly, train.Embarked is a Series object, applying Series.mode() \\\n",
    "#### returns a Series object of length 1 with the mode, so address with \\\n",
    "#### index 0. Apply Series.dropna() to exclude these from the mode() call.\n",
    "#### Use .loc to address row by number index, select column by header.\n",
    "for row_num in train.Embarked[train.Embarked.isnull()].index:\n",
    "    train.loc[row_num, 'Embarked'] = train.Embarked.dropna().mode().values[0]\n",
    "\n",
    "for row_num in test.Embarked[test.Embarked.isnull()].index:\n",
    "    test.loc[row_num, 'Embarked'] = test.Embarked.dropna().mode().values[0]\n",
    "\n",
    "### Embarked: Map strings to list of ports, then change strings to integers\n",
    "PORTS = list(enumerate(np.unique(train.Embarked)))\n",
    "PORTS_TEST = list(enumerate(np.unique(test.Embarked)))\n",
    "#### Shorthand dictionary assignment, name as key, list index as value\n",
    "PORTS_DICT = {name : i for i, name in PORTS}\n",
    "PORTS_DICT_TEST = {name : i for i, name in PORTS_TEST}\n",
    "#### Use a lambda function, map the existing Embarked data x to PORTS_DICT \\\n",
    "#### using x as key and setting new value to integer value.\n",
    "train.Embarked = train.Embarked.map(lambda x: PORTS_DICT[x]).astype(int)\n",
    "test.Embarked = test.Embarked.map(lambda x: PORTS_DICT_TEST[x]).astype(int)\n",
    "\n",
    "### Age: missing -> median of all ages\n",
    "AGE_MEDIAN = train.Age.dropna().median()\n",
    "for row_num in train.Age[train.Age.isnull()].index:\n",
    "    train.loc[row_num, 'Age'] = AGE_MEDIAN\n",
    "\n",
    "AGE_MEDIAN_TEST = test.Age.dropna().median()    \n",
    "for row_num in test.Age[test.Age.isnull()].index:\n",
    "    test.loc[row_num, 'Age'] = AGE_MEDIAN_TEST\n",
    "    \n",
    "### Fare: missing -> median for fare class\n",
    "MEDIAN_FARE_TEST = np.zeros(len(np.unique(test.Pclass)))\n",
    "for f in range(0,len(np.unique(test.Pclass))):\n",
    "    MEDIAN_FARE_TEST[f] = test.loc[test.Pclass == f+1, 'Fare'].dropna().median()\n",
    "\n",
    "for row_num in test.Fare[test.Fare.isnull()].index:\n",
    "    temp_pclass = test.loc[row_num, 'Pclass'] - 1\n",
    "    test.loc[row_num, 'Fare'] = MEDIAN_FARE_TEST[temp_pclass]\n",
    "\n",
    "### Remove redundant column(s), remove non-integer columns\n",
    "#### Sex is now redundant with IsMale, drop the column\n",
    "#### Cabin is absent for a large number of passengers, also non-integer\n",
    "#### Names are unique, non-integer\n",
    "#### Ticket numbers also unique, non-integer in many cases\n",
    "#### Must remove PassengerId or they become part of prediction, values nonsense\n",
    "train = train.drop(['Sex', 'Name', 'Ticket', 'Cabin', 'PassengerId'], axis=1)\n",
    "passenger_ids = test.PassengerId.values\n",
    "test = test.drop(['Sex', 'Name', 'Ticket', 'Cabin', 'PassengerId'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Survived\n",
      "892        0.0\n",
      "893        0.0\n",
      "894        0.0\n",
      "895        1.0\n",
      "896        0.0\n",
      "897        0.0\n",
      "898        0.0\n",
      "899        0.0\n",
      "900        1.0\n",
      "901        0.0\n",
      "902        0.0\n",
      "903        0.0\n",
      "904        1.0\n",
      "905        0.0\n",
      "906        1.0\n",
      "907        1.0\n",
      "908        0.0\n",
      "909        1.0\n",
      "910        0.0\n",
      "911        0.0\n",
      "912        1.0\n",
      "913        0.0\n",
      "914        1.0\n",
      "915        1.0\n",
      "916        1.0\n",
      "917        0.0\n",
      "918        1.0\n",
      "919        1.0\n",
      "920        1.0\n",
      "921        0.0\n",
      "...        ...\n",
      "1280       0.0\n",
      "1281       0.0\n",
      "1282       0.0\n",
      "1283       1.0\n",
      "1284       0.0\n",
      "1285       0.0\n",
      "1286       0.0\n",
      "1287       1.0\n",
      "1288       0.0\n",
      "1289       1.0\n",
      "1290       0.0\n",
      "1291       0.0\n",
      "1292       1.0\n",
      "1293       0.0\n",
      "1294       1.0\n",
      "1295       0.0\n",
      "1296       0.0\n",
      "1297       1.0\n",
      "1298       0.0\n",
      "1299       0.0\n",
      "1300       1.0\n",
      "1301       1.0\n",
      "1302       1.0\n",
      "1303       1.0\n",
      "1304       0.0\n",
      "1305       0.0\n",
      "1306       1.0\n",
      "1307       0.0\n",
      "1308       0.0\n",
      "1309       1.0\n",
      "\n",
      "[418 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# Cleaned data to np array\n",
    "train_data = train.values\n",
    "test_data = test.values\n",
    "\n",
    "# Train the forest\n",
    "forest = RandomForestClassifier(n_estimators=100)\n",
    "forest = forest.fit(train_data[0::, 1::], train_data[0::, 0])\n",
    "\n",
    "# Make a prediction\n",
    "output = forest.predict(test_data)\n",
    "\n",
    "# Write to file\n",
    "predictions_file = open(\"myfirstforest.csv\", \"w\")\n",
    "open_file_object = csv.writer(predictions_file)\n",
    "open_file_object.writerow([\"PassengerId\",\"Survived\"])\n",
    "open_file_object.writerows(zip(passenger_ids, output))\n",
    "predictions_file.close()\n",
    "\n",
    "# Print the result here as well\n",
    "print(pd.DataFrame(data=output, index=passenger_ids, columns=['Survived']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
